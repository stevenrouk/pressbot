{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn text data tutorial\n",
    "http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories=['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "data = fetch_20newsgroups(categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2257\n",
      "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']\n"
     ]
    }
   ],
   "source": [
    "print(len(data.data))\n",
    "print(data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Organization: The City University\n",
      "Lines: 14\n",
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "Please email any response.\n",
      "\n",
      "Is this the correct group?\n",
      "\n",
      "Thanks in advance.  Michael.\n",
      "-- \n",
      "Michael Collier (Programmer)                 The Computer Unit,\n",
      "Email: M.P.Collier@uk.ac.city                The City University,\n",
      "Tel: 071 477-8000 x3769                      London,\n",
      "Fax: 071 477-8565                            EC1V 0HB.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2257, 35788)\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(data.data)\n",
    "print(X_train_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4690"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2257, 35788)\n"
     ]
    }
   ],
   "source": [
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "print(X_train_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2257, 35788)\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(X_train_tfidf, data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = clf.predict(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God is love => soc.religion.christian\n",
      "'OpenGL on the GPU is fast => comp.graphics\n"
     ]
    }
   ],
   "source": [
    "for doc, category in zip(docs_new, predicted):\n",
    "    print(\"'{0} => {1}\".format(doc, data.target_names[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf = text_clf.fit(data.data, data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs_test = data_test.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 3, 0, 3, 0, 1, 3, 2, 3])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = text_clf.predict(docs_test)\n",
    "predicted[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83488681757656458"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predicted == data_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge',\n",
    "                                           penalty='l2',\n",
    "                                           alpha=1e-3,\n",
    "                                           n_iter=5,\n",
    "                                           random_state=42)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9127829560585885"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = text_clf.fit(data.data, data.target)\n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == data_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.95      0.81      0.87       319\n",
      "         comp.graphics       0.88      0.97      0.92       389\n",
      "               sci.med       0.94      0.90      0.92       396\n",
      "soc.religion.christian       0.90      0.95      0.93       398\n",
      "\n",
      "           avg / total       0.92      0.91      0.91      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(data_test.target, predicted,\n",
    "      target_names=data_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[258,  11,  15,  35],\n",
       "       [  4, 379,   3,   3],\n",
       "       [  5,  33, 355,   3],\n",
       "       [  5,  10,   4, 379]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(data_test.target, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...     penalty='l2', power_t=0.5, random_state=42, shuffle=True, verbose=0,\n",
       "       warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'clf__alpha': (0.01, 0.001), 'tfidf__use_idf': (True, False), 'vect__ngram_range': [(1, 1), (1, 2)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.fit(data.data[:400], data.target[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'soc.religion.christian'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names[gs_clf.predict(['God is love'])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "print(gs_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__alpha: '0.001'\n",
      "tfidf__use_idf: 'True'\n",
      "vect__ngram_range: '(1, 1)'\n"
     ]
    }
   ],
   "source": [
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"{0}: '{1}'\".format(param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# python lda package\n",
    "https://pypi.python.org/pypi/lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lda\n",
    "import lda.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = lda.datasets.load_reuters()\n",
    "vocab = lda.datasets.load_reuters_vocab()\n",
    "titles = lda.datasets.load_reuters_titles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4258"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395, 4258)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0 UK: Prince Charles spearheads British royal revolution. LONDON 1996-08-20',\n",
       " '1 GERMANY: Historic Dresden church rising from WW2 ashes. DRESDEN, Germany 1996-08-21',\n",
       " \"2 INDIA: Mother Teresa's condition said still unstable. CALCUTTA 1996-08-23\",\n",
       " '3 UK: Palace warns British weekly over Charles pictures. LONDON 1996-08-25',\n",
       " '4 INDIA: Mother Teresa, slightly stronger, blesses nuns. CALCUTTA 1996-08-25',\n",
       " \"5 INDIA: Mother Teresa's condition unchanged, thousands pray. CALCUTTA 1996-08-25\",\n",
       " '6 INDIA: Mother Teresa shows signs of strength, blesses nuns. CALCUTTA 1996-08-26',\n",
       " \"7 INDIA: Mother Teresa's condition improves, many pray. CALCUTTA, India 1996-08-25\",\n",
       " '8 INDIA: Mother Teresa improves, nuns pray for \"miracle\". CALCUTTA 1996-08-26',\n",
       " '9 UK: Charles under fire over prospect of Queen Camilla. LONDON 1996-08-26')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = lda.LDA(n_topics=20, n_iter=1500, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 395\n",
      "INFO:lda:vocab_size: 4258\n",
      "INFO:lda:n_words: 84010\n",
      "INFO:lda:n_topics: 20\n",
      "INFO:lda:n_iter: 1500\n",
      "INFO:lda:<0> log likelihood: -1051748\n",
      "INFO:lda:<10> log likelihood: -719800\n",
      "INFO:lda:<20> log likelihood: -699115\n",
      "INFO:lda:<30> log likelihood: -689370\n",
      "INFO:lda:<40> log likelihood: -684918\n",
      "INFO:lda:<50> log likelihood: -681322\n",
      "INFO:lda:<60> log likelihood: -678979\n",
      "INFO:lda:<70> log likelihood: -676598\n",
      "INFO:lda:<80> log likelihood: -675383\n",
      "INFO:lda:<90> log likelihood: -673316\n",
      "INFO:lda:<100> log likelihood: -672761\n",
      "INFO:lda:<110> log likelihood: -671320\n",
      "INFO:lda:<120> log likelihood: -669744\n",
      "INFO:lda:<130> log likelihood: -669292\n",
      "INFO:lda:<140> log likelihood: -667940\n",
      "INFO:lda:<150> log likelihood: -668038\n",
      "INFO:lda:<160> log likelihood: -667429\n",
      "INFO:lda:<170> log likelihood: -666475\n",
      "INFO:lda:<180> log likelihood: -665562\n",
      "INFO:lda:<190> log likelihood: -664920\n",
      "INFO:lda:<200> log likelihood: -664979\n",
      "INFO:lda:<210> log likelihood: -664722\n",
      "INFO:lda:<220> log likelihood: -664459\n",
      "INFO:lda:<230> log likelihood: -664360\n",
      "INFO:lda:<240> log likelihood: -663600\n",
      "INFO:lda:<250> log likelihood: -664164\n",
      "INFO:lda:<260> log likelihood: -663826\n",
      "INFO:lda:<270> log likelihood: -663458\n",
      "INFO:lda:<280> log likelihood: -663393\n",
      "INFO:lda:<290> log likelihood: -662904\n",
      "INFO:lda:<300> log likelihood: -662294\n",
      "INFO:lda:<310> log likelihood: -662031\n",
      "INFO:lda:<320> log likelihood: -662430\n",
      "INFO:lda:<330> log likelihood: -661601\n",
      "INFO:lda:<340> log likelihood: -662108\n",
      "INFO:lda:<350> log likelihood: -662152\n",
      "INFO:lda:<360> log likelihood: -661899\n",
      "INFO:lda:<370> log likelihood: -661012\n",
      "INFO:lda:<380> log likelihood: -661278\n",
      "INFO:lda:<390> log likelihood: -661085\n",
      "INFO:lda:<400> log likelihood: -660418\n",
      "INFO:lda:<410> log likelihood: -660510\n",
      "INFO:lda:<420> log likelihood: -660343\n",
      "INFO:lda:<430> log likelihood: -659789\n",
      "INFO:lda:<440> log likelihood: -659336\n",
      "INFO:lda:<450> log likelihood: -659039\n",
      "INFO:lda:<460> log likelihood: -659329\n",
      "INFO:lda:<470> log likelihood: -658707\n",
      "INFO:lda:<480> log likelihood: -658879\n",
      "INFO:lda:<490> log likelihood: -658819\n",
      "INFO:lda:<500> log likelihood: -658407\n",
      "INFO:lda:<510> log likelihood: -658651\n",
      "INFO:lda:<520> log likelihood: -658111\n",
      "INFO:lda:<530> log likelihood: -658018\n",
      "INFO:lda:<540> log likelihood: -658111\n",
      "INFO:lda:<550> log likelihood: -657925\n",
      "INFO:lda:<560> log likelihood: -657860\n",
      "INFO:lda:<570> log likelihood: -657494\n",
      "INFO:lda:<580> log likelihood: -657723\n",
      "INFO:lda:<590> log likelihood: -657591\n",
      "INFO:lda:<600> log likelihood: -657557\n",
      "INFO:lda:<610> log likelihood: -657505\n",
      "INFO:lda:<620> log likelihood: -657730\n",
      "INFO:lda:<630> log likelihood: -657304\n",
      "INFO:lda:<640> log likelihood: -657208\n",
      "INFO:lda:<650> log likelihood: -657518\n",
      "INFO:lda:<660> log likelihood: -657541\n",
      "INFO:lda:<670> log likelihood: -657381\n",
      "INFO:lda:<680> log likelihood: -657575\n",
      "INFO:lda:<690> log likelihood: -656985\n",
      "INFO:lda:<700> log likelihood: -656815\n",
      "INFO:lda:<710> log likelihood: -656930\n",
      "INFO:lda:<720> log likelihood: -656538\n",
      "INFO:lda:<730> log likelihood: -656291\n",
      "INFO:lda:<740> log likelihood: -656417\n",
      "INFO:lda:<750> log likelihood: -656747\n",
      "INFO:lda:<760> log likelihood: -656600\n",
      "INFO:lda:<770> log likelihood: -656269\n",
      "INFO:lda:<780> log likelihood: -656311\n",
      "INFO:lda:<790> log likelihood: -656069\n",
      "INFO:lda:<800> log likelihood: -656228\n",
      "INFO:lda:<810> log likelihood: -656178\n",
      "INFO:lda:<820> log likelihood: -655694\n",
      "INFO:lda:<830> log likelihood: -655997\n",
      "INFO:lda:<840> log likelihood: -656224\n",
      "INFO:lda:<850> log likelihood: -656197\n",
      "INFO:lda:<860> log likelihood: -655889\n",
      "INFO:lda:<870> log likelihood: -656180\n",
      "INFO:lda:<880> log likelihood: -656997\n",
      "INFO:lda:<890> log likelihood: -655989\n",
      "INFO:lda:<900> log likelihood: -655615\n",
      "INFO:lda:<910> log likelihood: -655584\n",
      "INFO:lda:<920> log likelihood: -656602\n",
      "INFO:lda:<930> log likelihood: -656083\n",
      "INFO:lda:<940> log likelihood: -656294\n",
      "INFO:lda:<950> log likelihood: -656257\n",
      "INFO:lda:<960> log likelihood: -656243\n",
      "INFO:lda:<970> log likelihood: -656028\n",
      "INFO:lda:<980> log likelihood: -655603\n",
      "INFO:lda:<990> log likelihood: -656012\n",
      "INFO:lda:<1000> log likelihood: -655849\n",
      "INFO:lda:<1010> log likelihood: -655376\n",
      "INFO:lda:<1020> log likelihood: -655417\n",
      "INFO:lda:<1030> log likelihood: -655856\n",
      "INFO:lda:<1040> log likelihood: -655197\n",
      "INFO:lda:<1050> log likelihood: -655938\n",
      "INFO:lda:<1060> log likelihood: -655529\n",
      "INFO:lda:<1070> log likelihood: -655092\n",
      "INFO:lda:<1080> log likelihood: -655119\n",
      "INFO:lda:<1090> log likelihood: -656215\n",
      "INFO:lda:<1100> log likelihood: -655602\n",
      "INFO:lda:<1110> log likelihood: -655296\n",
      "INFO:lda:<1120> log likelihood: -655547\n",
      "INFO:lda:<1130> log likelihood: -655580\n",
      "INFO:lda:<1140> log likelihood: -655604\n",
      "INFO:lda:<1150> log likelihood: -655168\n",
      "INFO:lda:<1160> log likelihood: -655281\n",
      "INFO:lda:<1170> log likelihood: -655409\n",
      "INFO:lda:<1180> log likelihood: -655517\n",
      "INFO:lda:<1190> log likelihood: -654922\n",
      "INFO:lda:<1200> log likelihood: -655304\n",
      "INFO:lda:<1210> log likelihood: -655852\n",
      "INFO:lda:<1220> log likelihood: -655184\n",
      "INFO:lda:<1230> log likelihood: -655650\n",
      "INFO:lda:<1240> log likelihood: -655606\n",
      "INFO:lda:<1250> log likelihood: -656086\n",
      "INFO:lda:<1260> log likelihood: -655698\n",
      "INFO:lda:<1270> log likelihood: -655351\n",
      "INFO:lda:<1280> log likelihood: -655686\n",
      "INFO:lda:<1290> log likelihood: -654801\n",
      "INFO:lda:<1300> log likelihood: -654973\n",
      "INFO:lda:<1310> log likelihood: -655186\n",
      "INFO:lda:<1320> log likelihood: -655128\n",
      "INFO:lda:<1330> log likelihood: -655365\n",
      "INFO:lda:<1340> log likelihood: -655338\n",
      "INFO:lda:<1350> log likelihood: -655219\n",
      "INFO:lda:<1360> log likelihood: -655115\n",
      "INFO:lda:<1370> log likelihood: -654930\n",
      "INFO:lda:<1380> log likelihood: -655209\n",
      "INFO:lda:<1390> log likelihood: -654940\n",
      "INFO:lda:<1400> log likelihood: -655055\n",
      "INFO:lda:<1410> log likelihood: -655286\n",
      "INFO:lda:<1420> log likelihood: -655316\n",
      "INFO:lda:<1430> log likelihood: -655257\n",
      "INFO:lda:<1440> log likelihood: -654964\n",
      "INFO:lda:<1450> log likelihood: -654884\n",
      "INFO:lda:<1460> log likelihood: -655493\n",
      "INFO:lda:<1470> log likelihood: -655415\n",
      "INFO:lda:<1480> log likelihood: -655192\n",
      "INFO:lda:<1490> log likelihood: -655728\n",
      "INFO:lda:<1499> log likelihood: -655858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lda.lda.LDA at 0x7fbc5c2a8dd8>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_word = model.topic_word_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_top_words = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: british churchill sale million major letters west britain\n",
      "Topic 1: church government political country state people party against\n",
      "Topic 2: elvis king fans presley life concert young death\n",
      "Topic 3: yeltsin russian russia president kremlin moscow michael operation\n",
      "Topic 4: pope vatican paul john surgery hospital pontiff rome\n",
      "Topic 5: family funeral police miami versace cunanan city service\n",
      "Topic 6: simpson former years court president wife south church\n",
      "Topic 7: order mother successor election nuns church nirmala head\n",
      "Topic 8: charles prince diana royal king queen parker bowles\n",
      "Topic 9: film french france against bardot paris poster animal\n",
      "Topic 10: germany german war nazi letter christian book jews\n",
      "Topic 11: east peace prize award timor quebec belo leader\n",
      "Topic 12: n't life show told very love television father\n",
      "Topic 13: years year time last church world people say\n",
      "Topic 14: mother teresa heart calcutta charity nun hospital missionaries\n",
      "Topic 15: city salonika capital buddhist cultural vietnam byzantine show\n",
      "Topic 16: music tour opera singer israel people film israeli\n",
      "Topic 17: church catholic bernardin cardinal bishop wright death cancer\n",
      "Topic 18: harriman clinton u.s ambassador paris president churchill france\n",
      "Topic 19: city museum art exhibition century million churches set\n"
     ]
    }
   ],
   "source": [
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    print('Topic {0}: {1}'.format(i, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 UK: Prince Charles spearheads British royal revolution. LONDON 1996-08-20 (top topic: 8)\n",
      "1 GERMANY: Historic Dresden church rising from WW2 ashes. DRESDEN, Germany 1996-08-21 (top topic: 13)\n",
      "2 INDIA: Mother Teresa's condition said still unstable. CALCUTTA 1996-08-23 (top topic: 14)\n",
      "3 UK: Palace warns British weekly over Charles pictures. LONDON 1996-08-25 (top topic: 8)\n",
      "4 INDIA: Mother Teresa, slightly stronger, blesses nuns. CALCUTTA 1996-08-25 (top topic: 14)\n",
      "5 INDIA: Mother Teresa's condition unchanged, thousands pray. CALCUTTA 1996-08-25 (top topic: 14)\n",
      "6 INDIA: Mother Teresa shows signs of strength, blesses nuns. CALCUTTA 1996-08-26 (top topic: 14)\n",
      "7 INDIA: Mother Teresa's condition improves, many pray. CALCUTTA, India 1996-08-25 (top topic: 14)\n",
      "8 INDIA: Mother Teresa improves, nuns pray for \"miracle\". CALCUTTA 1996-08-26 (top topic: 14)\n",
      "9 UK: Charles under fire over prospect of Queen Camilla. LONDON 1996-08-26 (top topic: 8)\n"
     ]
    }
   ],
   "source": [
    "doc_topic = model.doc_topic_\n",
    "for i in range(10):\n",
    "    print(\"{0} (top topic: {1})\".format(titles[i], doc_topic[i].argmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple example first\n",
    "https://radimrehurek.com/gensim/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora, similarities, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = [[(0, 1.0), (1, 1.0), (2, 1.0)],\n",
    "          [(2, 1.0), (3, 1.0), (4, 1.0), (5, 1.0), (6, 1.0), (8, 1.0)],\n",
    "          [(1, 1.0), (3, 1.0), (4, 1.0), (7, 1.0)],\n",
    "          [(0, 1.0), (4, 2.0), (7, 1.0)],\n",
    "          [(3, 1.0), (5, 1.0), (6, 1.0)],\n",
    "          [(9, 1.0)],\n",
    "          [(9, 1.0), (10, 1.0)],\n",
    "          [(9, 1.0), (10, 1.0), (11, 1.0)],\n",
    "          [(8, 1.0), (10, 1.0), (11, 1.0)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.tfidfmodel:collecting document frequencies\n",
      "INFO:gensim.models.tfidfmodel:PROGRESS: processing document #0\n",
      "INFO:gensim.models.tfidfmodel:calculating IDF weights for 9 documents and 11 features (28 matrix non-zeros)\n"
     ]
    }
   ],
   "source": [
    "tfidf = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.8075244024440723), (4, 0.5898341626740045)]\n"
     ]
    }
   ],
   "source": [
    "vec = [(0, 1), (4, 1)]\n",
    "print(tfidf[vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.similarities.docsim:creating sparse index\n",
      "INFO:gensim.matutils:creating sparse matrix from corpus\n",
      "INFO:gensim.matutils:PROGRESS: at document #0\n",
      "INFO:gensim.similarities.docsim:created <9x12 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 28 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.4662244), (1, 0.19139354), (2, 0.24600551), (3, 0.82094586), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.0), (8, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "sims = index[tfidf[vec]]\n",
    "print(list(enumerate(sims)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now the tutorials: tutorial 1\n",
    "https://radimrehurek.com/gensim/tut1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "             \"A survey of user opinion of computer system response time\",\n",
    "             \"The EPS user interface management system\",\n",
    "             \"System and human system engineering testing of EPS\",\n",
    "             \"Relation of user perceived response time to error measurement\",\n",
    "             \"The generation of random binary unordered trees\",\n",
    "             \"The intersection graph of paths in trees\",\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "             \"Graph minors A survey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'interface', 'computer'],\n",
      " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
      " ['eps', 'user', 'interface', 'system'],\n",
      " ['system', 'human', 'system', 'eps'],\n",
      " ['user', 'response', 'time'],\n",
      " ['trees'],\n",
      " ['graph', 'trees'],\n",
      " ['graph', 'minors', 'trees'],\n",
      " ['graph', 'minors', 'survey']]\n"
     ]
    }
   ],
   "source": [
    "# remove common words and tokenize\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "         for document in documents]\n",
    "\n",
    "# remove words that appear only once\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [[token for token in text if frequency[token] > 1]\n",
    "         for text in texts]\n",
    "\n",
    "from pprint import pprint  # pretty-printer\n",
    "pprint(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.corpora.dictionary:adding document #0 to Dictionary(0 unique tokens: [])\n",
      "INFO:gensim.corpora.dictionary:built Dictionary(12 unique tokens: ['computer', 'interface', 'eps', 'response', 'trees']...) from 9 documents (total 29 corpus positions)\n",
      "INFO:gensim.utils:saving Dictionary object under /tmp/deerwester.dict, separately None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12 unique tokens: ['computer', 'interface', 'eps', 'response', 'trees']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.save('/tmp/deerwester.dict')  # store the dictionary, for future reference\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'computer': 0, 'interface': 1, 'eps': 8, 'response': 3, 'trees': 9, 'user': 5, 'graph': 10, 'minors': 11, 'survey': 4, 'human': 2, 'system': 6, 'time': 7}\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12 unique tokens: ['computer', 'interface', 'eps', 'response', 'trees']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (2, 1)]\n"
     ]
    }
   ],
   "source": [
    "new_doc = \"Human computer interaction\"\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
    "print(new_vec)   # the word 'interaction' does not appear in the dictionary and is ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.corpora.mmcorpus:storing corpus in Matrix Market format to /tmp/deerwester.mm\n",
      "INFO:gensim.matutils:saving sparse matrix to /tmp/deerwester.mm\n",
      "INFO:gensim.matutils:PROGRESS: saving document #0\n",
      "INFO:gensim.matutils:saved 9x12 matrix, density=25.926% (28/108)\n",
      "INFO:gensim.corpora.indexedcorpus:saving MmCorpus index to /tmp/deerwester.mm.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1)], [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)], [(1, 1), (5, 1), (6, 1), (8, 1)], [(2, 1), (6, 2), (8, 1)], [(3, 1), (5, 1), (7, 1)], [(9, 1)], [(9, 1), (10, 1)], [(9, 1), (10, 1), (11, 1)], [(4, 1), (10, 1), (11, 1)]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpora.MmCorpus.serialize('/tmp/deerwester.mm', corpus)  # store to disk, for later use\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# memory-friendly corpus streaming, one document at a time\n",
    "class MyCorpus(object):\n",
    "    def __iter__(self):\n",
    "        for line in open('/tmp/mycorpus.txt'):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield dictionary.doc2bow(line.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MyCorpus object at 0x7fbc4419bac8>\n"
     ]
    }
   ],
   "source": [
    "corpus_memory_friendly = MyCorpus()\n",
    "print(corpus_memory_friendly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1)]\n",
      "[(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]\n",
      "[(1, 1), (5, 1), (6, 1), (8, 1)]\n",
      "[(2, 1), (6, 2), (8, 1)]\n",
      "[(3, 1), (5, 1), (7, 1)]\n",
      "[(9, 1)]\n",
      "[(9, 1), (10, 1)]\n",
      "[(9, 1), (10, 1), (11, 1)]\n",
      "[(4, 1), (10, 1), (11, 1)]\n"
     ]
    }
   ],
   "source": [
    "for vector in corpus_memory_friendly:\n",
    "    print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tutorial 2\n",
    "https://radimrehurek.com/gensim/tut2.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading Dictionary object from /tmp/deerwester.dict\n",
      "INFO:gensim.corpora.indexedcorpus:loaded corpus index from /tmp/deerwester.mm.index\n",
      "INFO:gensim.matutils:initializing corpus reader from /tmp/deerwester.mm\n",
      "INFO:gensim.matutils:accepted corpus with 9 documents, 12 features, 28 non-zero entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used files generated from first tutorial\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "if (os.path.exists(\"/tmp/deerwester.dict\")):\n",
    "   dictionary = corpora.Dictionary.load('/tmp/deerwester.dict')\n",
    "   corpus = corpora.MmCorpus('/tmp/deerwester.mm')\n",
    "   print(\"Used files generated from first tutorial\")\n",
    "else:\n",
    "   print(\"Please run first tutorial to generate data set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.tfidfmodel:collecting document frequencies\n",
      "INFO:gensim.models.tfidfmodel:PROGRESS: processing document #0\n",
      "INFO:gensim.models.tfidfmodel:calculating IDF weights for 9 documents and 11 features (28 matrix non-zeros)\n"
     ]
    }
   ],
   "source": [
    "tfidf = models.TfidfModel(corpus) # step 1 -- initialize a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.7071067811865476), (1, 0.7071067811865476)]\n"
     ]
    }
   ],
   "source": [
    "doc_bow = [(0, 1), (1, 1)]\n",
    "print(tfidf[doc_bow]) # step 2 -- use the model to transform vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.5773502691896257), (1, 0.5773502691896257), (2, 0.5773502691896257)]\n",
      "[(0, 0.44424552527467476), (3, 0.44424552527467476), (4, 0.44424552527467476), (5, 0.3244870206138555), (6, 0.3244870206138555), (7, 0.44424552527467476)]\n",
      "[(1, 0.5710059809418182), (5, 0.4170757362022777), (6, 0.4170757362022777), (8, 0.5710059809418182)]\n",
      "[(2, 0.49182558987264147), (6, 0.7184811607083769), (8, 0.49182558987264147)]\n",
      "[(3, 0.6282580468670046), (5, 0.45889394536615247), (7, 0.6282580468670046)]\n",
      "[(9, 1.0)]\n",
      "[(9, 0.7071067811865475), (10, 0.7071067811865475)]\n",
      "[(9, 0.5080429008916749), (10, 0.5080429008916749), (11, 0.695546419520037)]\n",
      "[(4, 0.6282580468670046), (10, 0.45889394536615247), (11, 0.6282580468670046)]\n"
     ]
    }
   ],
   "source": [
    "corpus_tfidf = tfidf[corpus]\n",
    "for doc in corpus_tfidf:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.lsimodel:using serial LSI version on this node\n",
      "INFO:gensim.models.lsimodel:updating model with new documents\n",
      "INFO:gensim.models.lsimodel:preparing a new chunk of documents\n",
      "INFO:gensim.models.lsimodel:using 100 extra samples and 2 power iterations\n",
      "INFO:gensim.models.lsimodel:1st phase: constructing (12, 102) action matrix\n",
      "INFO:gensim.models.lsimodel:orthonormalizing (12, 102) action matrix\n",
      "INFO:gensim.models.lsimodel:2nd phase: running dense svd on (12, 9) matrix\n",
      "INFO:gensim.models.lsimodel:computing the final decomposition\n",
      "INFO:gensim.models.lsimodel:keeping 2 factors (discarding 47.565% of energy spectrum)\n",
      "INFO:gensim.models.lsimodel:processed documents up to #9\n",
      "INFO:gensim.models.lsimodel:topic #0(1.594): 0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"time\" + 0.060*\"response\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"\n",
      "INFO:gensim.models.lsimodel:topic #1(1.476): -0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"response\" + -0.320*\"time\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"\n"
     ]
    }
   ],
   "source": [
    "# Transformations can also be serialized, one on top of another, in a sort of chain:\n",
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2) # initialize an LSI transformation\n",
    "corpus_lsi = lsi[corpus_tfidf] # create a double wrapper over the original corpus: bow->tfidf->fold-in-lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.lsimodel:topic #0(1.594): 0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"time\" + 0.060*\"response\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"\n",
      "INFO:gensim.models.lsimodel:topic #1(1.476): -0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"response\" + -0.320*\"time\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"time\" + 0.060*\"response\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"'),\n",
       " (1,\n",
       "  '-0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"response\" + -0.320*\"time\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"')]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.print_topics(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.066007833960904982), (1, -0.52007033063618591)]\n",
      "[(0, 0.19667592859142663), (1, -0.76095631677000486)]\n",
      "[(0, 0.08992639972446613), (1, -0.7241860626752511)]\n",
      "[(0, 0.075858476521783361), (1, -0.632055158600343)]\n",
      "[(0, 0.10150299184980255), (1, -0.57373084830029542)]\n",
      "[(0, 0.70321089393783076), (1, 0.16115180214025968)]\n",
      "[(0, 0.87747876731198282), (1, 0.16758906864659642)]\n",
      "[(0, 0.90986246868185738), (1, 0.1408655362871927)]\n",
      "[(0, 0.61658253505692806), (1, -0.053929075663891851)]\n"
     ]
    }
   ],
   "source": [
    "for doc in corpus_lsi: # both bow->tfidf and tfidf->lsi transformations are actually executed here, on the fly\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:saving Projection object under /tmp/model.lsi.projection, separately None\n",
      "INFO:gensim.utils:saving LsiModel object under /tmp/model.lsi, separately None\n",
      "INFO:gensim.utils:not storing attribute dispatcher\n",
      "INFO:gensim.utils:not storing attribute projection\n",
      "INFO:gensim.utils:loading LsiModel object from /tmp/model.lsi\n",
      "INFO:gensim.utils:loading id2word recursively from /tmp/model.lsi.id2word.* with mmap=None\n",
      "INFO:gensim.utils:setting ignored attribute dispatcher to None\n",
      "INFO:gensim.utils:setting ignored attribute projection to None\n",
      "INFO:gensim.utils:loading LsiModel object from /tmp/model.lsi.projection\n"
     ]
    }
   ],
   "source": [
    "lsi.save('/tmp/model.lsi') # same for tfidf, lda, ...\n",
    "lsi = models.LsiModel.load('/tmp/model.lsi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.tfidfmodel:collecting document frequencies\n",
      "INFO:gensim.models.tfidfmodel:PROGRESS: processing document #0\n",
      "INFO:gensim.models.tfidfmodel:calculating IDF weights for 9 documents and 11 features (28 matrix non-zeros)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "model = models.TfidfModel(corpus, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.lsimodel:using serial LSI version on this node\n",
      "INFO:gensim.models.lsimodel:updating model with new documents\n",
      "INFO:gensim.models.lsimodel:preparing a new chunk of documents\n",
      "INFO:gensim.models.lsimodel:using 100 extra samples and 2 power iterations\n",
      "INFO:gensim.models.lsimodel:1st phase: constructing (12, 400) action matrix\n",
      "INFO:gensim.models.lsimodel:orthonormalizing (12, 400) action matrix\n",
      "INFO:gensim.models.lsimodel:2nd phase: running dense svd on (12, 9) matrix\n",
      "INFO:gensim.models.lsimodel:computing the final decomposition\n",
      "INFO:gensim.models.lsimodel:keeping 9 factors (discarding 0.000% of energy spectrum)\n",
      "INFO:gensim.models.lsimodel:processed documents up to #9\n",
      "INFO:gensim.models.lsimodel:topic #0(3.341): 0.644*\"system\" + 0.404*\"user\" + 0.301*\"eps\" + 0.265*\"time\" + 0.265*\"response\" + 0.240*\"computer\" + 0.221*\"human\" + 0.206*\"survey\" + 0.198*\"interface\" + 0.036*\"graph\"\n",
      "INFO:gensim.models.lsimodel:topic #1(2.542): 0.623*\"graph\" + 0.490*\"trees\" + 0.451*\"minors\" + 0.274*\"survey\" + -0.167*\"system\" + -0.141*\"eps\" + -0.113*\"human\" + 0.107*\"response\" + 0.107*\"time\" + -0.072*\"interface\"\n",
      "INFO:gensim.models.lsimodel:topic #2(2.354): 0.426*\"response\" + 0.426*\"time\" + -0.361*\"system\" + 0.338*\"user\" + -0.330*\"eps\" + -0.289*\"human\" + -0.231*\"trees\" + -0.223*\"graph\" + 0.178*\"survey\" + 0.164*\"computer\"\n",
      "INFO:gensim.models.lsimodel:topic #3(1.645): 0.595*\"computer\" + 0.552*\"interface\" + 0.415*\"human\" + -0.333*\"system\" + -0.188*\"eps\" + -0.099*\"user\" + -0.074*\"time\" + -0.074*\"response\" + 0.032*\"survey\" + -0.025*\"trees\"\n",
      "INFO:gensim.models.lsimodel:topic #4(1.505): -0.594*\"trees\" + 0.537*\"survey\" + -0.332*\"user\" + 0.300*\"minors\" + -0.282*\"interface\" + 0.159*\"system\" + -0.115*\"eps\" + 0.107*\"computer\" + 0.106*\"human\" + -0.080*\"response\"\n"
     ]
    }
   ],
   "source": [
    "# Latent Semantic Indexing (LSI, or sometimes LSA)\n",
    "model = models.LsiModel(corpus, id2word=dictionary, num_topics=300)  # should be tfidf_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:using symmetric alpha at 0.01\n",
      "INFO:gensim.models.ldamodel:using symmetric eta at 0.01\n",
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "INFO:gensim.models.ldamodel:running online LDA training, 100 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "INFO:gensim.models.ldamodel:-115.905 per-word bound, 77766935683978659199970645983100928.0 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #9/9\n",
      "INFO:gensim.models.ldamodel:topic #32 (0.010): 0.083*time + 0.083*user + 0.083*graph + 0.083*trees + 0.083*eps + 0.083*computer + 0.083*system + 0.083*human + 0.083*response + 0.083*interface\n",
      "INFO:gensim.models.ldamodel:topic #13 (0.010): 0.083*time + 0.083*user + 0.083*graph + 0.083*trees + 0.083*eps + 0.083*computer + 0.083*system + 0.083*human + 0.083*response + 0.083*interface\n",
      "INFO:gensim.models.ldamodel:topic #98 (0.010): 0.324*user + 0.324*response + 0.324*time + 0.003*graph + 0.003*trees + 0.003*eps + 0.003*computer + 0.003*human + 0.003*survey + 0.003*system\n",
      "INFO:gensim.models.ldamodel:topic #24 (0.010): 0.324*graph + 0.324*trees + 0.324*minors + 0.003*time + 0.003*eps + 0.003*computer + 0.003*system + 0.003*human + 0.003*response + 0.003*interface\n",
      "INFO:gensim.models.ldamodel:topic #77 (0.010): 0.083*time + 0.083*user + 0.083*graph + 0.083*trees + 0.083*eps + 0.083*computer + 0.083*system + 0.083*human + 0.083*response + 0.083*interface\n",
      "INFO:gensim.models.ldamodel:topic diff=87.392628, rho=1.000000\n"
     ]
    }
   ],
   "source": [
    "# Latent Dirirchlet Allocation\n",
    "model = models.LdaModel(corpus, id2word=dictionary, num_topics=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.hdpmodel:topic 0: 0.302*time + 0.149*graph + 0.139*eps + 0.139*minors + 0.075*user + 0.073*response + 0.044*survey + 0.035*interface + 0.016*computer + 0.012*human + 0.010*trees + 0.006*system\n",
      "INFO:gensim.models.hdpmodel:topic 1: 0.311*minors + 0.247*human + 0.171*survey + 0.091*graph + 0.070*user + 0.040*interface + 0.032*eps + 0.014*trees + 0.012*system + 0.009*computer + 0.002*time + 0.001*response\n",
      "INFO:gensim.models.hdpmodel:topic 2: 0.264*time + 0.142*response + 0.136*survey + 0.100*trees + 0.068*minors + 0.064*interface + 0.061*system + 0.051*user + 0.037*graph + 0.036*eps + 0.026*human + 0.015*computer\n",
      "INFO:gensim.models.hdpmodel:topic 3: 0.419*graph + 0.136*trees + 0.112*human + 0.076*survey + 0.071*user + 0.064*response + 0.047*computer + 0.040*minors + 0.018*eps + 0.007*time + 0.006*interface + 0.004*system\n",
      "INFO:gensim.models.hdpmodel:topic 4: 0.271*user + 0.200*trees + 0.121*graph + 0.081*computer + 0.065*survey + 0.059*eps + 0.057*minors + 0.044*interface + 0.037*response + 0.035*time + 0.018*human + 0.011*system\n",
      "INFO:gensim.models.hdpmodel:topic 5: 0.273*computer + 0.125*human + 0.119*graph + 0.096*system + 0.069*time + 0.068*minors + 0.066*eps + 0.054*survey + 0.046*response + 0.035*interface + 0.033*trees + 0.016*user\n",
      "INFO:gensim.models.hdpmodel:topic 6: 0.330*eps + 0.139*trees + 0.129*time + 0.118*graph + 0.077*human + 0.061*computer + 0.054*survey + 0.050*system + 0.017*response + 0.016*user + 0.008*interface + 0.002*minors\n",
      "INFO:gensim.models.hdpmodel:topic 7: 0.269*trees + 0.146*eps + 0.129*time + 0.111*system + 0.070*interface + 0.067*user + 0.044*minors + 0.043*response + 0.038*computer + 0.037*human + 0.030*survey + 0.015*graph\n",
      "INFO:gensim.models.hdpmodel:topic 8: 0.368*survey + 0.308*system + 0.118*trees + 0.057*minors + 0.056*time + 0.033*user + 0.021*graph + 0.010*human + 0.009*computer + 0.008*eps + 0.006*response + 0.004*interface\n",
      "INFO:gensim.models.hdpmodel:topic 9: 0.166*graph + 0.145*time + 0.143*computer + 0.128*human + 0.079*system + 0.079*eps + 0.062*minors + 0.061*response + 0.056*interface + 0.051*trees + 0.024*survey + 0.006*user\n",
      "INFO:gensim.models.hdpmodel:topic 10: 0.210*response + 0.188*survey + 0.175*computer + 0.102*minors + 0.068*trees + 0.067*time + 0.062*graph + 0.054*eps + 0.027*human + 0.024*user + 0.013*interface + 0.010*system\n",
      "INFO:gensim.models.hdpmodel:topic 11: 0.263*eps + 0.243*trees + 0.144*user + 0.101*computer + 0.088*graph + 0.051*system + 0.040*response + 0.023*interface + 0.019*time + 0.013*survey + 0.013*human + 0.003*minors\n",
      "INFO:gensim.models.hdpmodel:topic 12: 0.341*user + 0.288*survey + 0.086*eps + 0.077*human + 0.065*time + 0.040*minors + 0.029*graph + 0.022*computer + 0.020*response + 0.016*interface + 0.012*system + 0.002*trees\n",
      "INFO:gensim.models.hdpmodel:topic 13: 0.175*user + 0.119*human + 0.118*response + 0.114*system + 0.098*minors + 0.085*graph + 0.076*trees + 0.069*interface + 0.059*computer + 0.044*time + 0.038*eps + 0.006*survey\n",
      "INFO:gensim.models.hdpmodel:topic 14: 0.267*time + 0.189*system + 0.091*graph + 0.082*trees + 0.080*user + 0.069*human + 0.056*minors + 0.056*interface + 0.037*computer + 0.031*eps + 0.027*response + 0.016*survey\n",
      "INFO:gensim.models.hdpmodel:topic 15: 0.341*trees + 0.160*survey + 0.150*minors + 0.128*interface + 0.107*computer + 0.029*time + 0.023*human + 0.023*system + 0.013*response + 0.012*graph + 0.011*eps + 0.002*user\n",
      "INFO:gensim.models.hdpmodel:topic 16: 0.314*response + 0.166*trees + 0.165*time + 0.121*computer + 0.068*system + 0.060*user + 0.060*survey + 0.016*graph + 0.011*eps + 0.009*human + 0.006*minors + 0.004*interface\n",
      "INFO:gensim.models.hdpmodel:topic 17: 0.151*interface + 0.139*graph + 0.136*user + 0.090*survey + 0.083*human + 0.083*eps + 0.082*system + 0.067*time + 0.063*response + 0.049*computer + 0.029*minors + 0.027*trees\n",
      "INFO:gensim.models.hdpmodel:topic 18: 0.302*graph + 0.175*trees + 0.150*survey + 0.107*user + 0.065*eps + 0.047*interface + 0.042*time + 0.033*human + 0.029*response + 0.027*computer + 0.014*system + 0.007*minors\n",
      "INFO:gensim.models.hdpmodel:topic 19: 0.220*trees + 0.186*user + 0.123*graph + 0.113*time + 0.111*response + 0.090*computer + 0.041*human + 0.030*minors + 0.028*interface + 0.022*system + 0.021*survey + 0.016*eps\n"
     ]
    }
   ],
   "source": [
    "# Hierarchical Dirichlet Process\n",
    "model = models.HdpModel(corpus, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seminal Papers\n",
    "\n",
    "- Deerwester, LSI: http://lsa3.colorado.edu/papers/JASIS.lsi.90.pdf\n",
    "- Blei, LDA: https://www.cs.princeton.edu/~blei/papers/BleiNgJordan2003.pdf\n",
    "- Blei, Online LDA: http://www.cs.princeton.edu/~blei/papers/HoffmanBleiBach2010b.pdf\n",
    "\n",
    "## Other Tutorials\n",
    "\n",
    "- http://chrisstrelioff.ws/sandbox/2014/11/13/getting_started_with_latent_dirichlet_allocation_in_python.html\n",
    "- https://ariddell.org/lda.html\n",
    "- https://rstudio-pubs-static.s3.amazonaws.com/79360_850b2a69980c4488b1db95987a24867a.html\n",
    "- https://de.dariah.eu/tatom/topic_model_mallet.html#topic-model-mallet\n",
    "- https://de.dariah.eu/tatom/topic_model_python.html\n",
    "\n",
    "## Resources\n",
    "\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pressbot-env]",
   "language": "python",
   "name": "conda-env-pressbot-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
